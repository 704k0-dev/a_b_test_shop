# Hypothesis Prioritization and A/B Test Analysis for an Online Store

## Project Description

This project is part of an exercise carried out during a Data Analyst bootcamp. As an analyst in an online store, I worked alongside the marketing department to prioritize a list of hypotheses that could potentially increase revenue. Afterward, I conducted an analysis of an A/B test based on these hypotheses.

The project consists of two main parts:
1. **Hypothesis Prioritization**: Evaluating hypotheses using the **ICE** and **RICE** frameworks.
2. **A/B Test Analysis**: Evaluating the results of the A/B test with statistical and graphical analyses.

## Data Description

The project uses three different datasets: one for hypothesis prioritization and two for A/B test analysis.

### Data for Hypothesis Prioritization:

- **hypotheses_us.csv**:
  - **Hypotheses**: Brief description of each hypothesis.
  - **Reach**: User reach, on a scale of 1 to 10.
  - **Impact**: Expected impact on users, on a scale of 1 to 10.
  - **Confidence**: Confidence in the hypothesis, on a scale of 1 to 10.
  - **Effort**: Resources needed to test the hypothesis, on a scale of 1 to 10. The higher the Effort value, the more resources the test requires.

### Data for A/B Test Analysis:

1. **orders_us.csv**:
   - **transactionId**: Unique order identifier.
   - **visitorId**: Identifier of the user who placed the order.
   - **date**: Order date.
   - **revenue**: Revenue generated by the order.
   - **group**: The A/B test group to which the user belongs (A or B).

2. **visits_us.csv**:
   - **date**: Visit date.
   - **group**: The A/B test group to which the user belongs (A or B).
   - **visits**: Number of visits on the specified date and test group.

### Preprocessing:
Data preprocessing was applied to correct potential errors, such as visitors appearing in both A/B test groups, which could skew the results.

## Part 1: Hypothesis Prioritization

In this part, I worked with the `hypotheses_us.csv` file, which contains 9 hypotheses on how to increase revenue in the online store. Two prioritization frameworks were applied: **ICE** and **RICE**.

- **ICE (Impact, Confidence, Effort)**: A simple framework that prioritizes hypotheses with the highest impact and confidence and the least effort.
- **RICE (Reach, Impact, Confidence, Effort)**: Similar to ICE, but considers **reach** to account for the number of users who could be affected by the hypothesis.

### Analysis:

1. **Prioritizing hypotheses using ICE**: 
   Hypotheses were ranked using the formula:
   \[
   ICE = \frac{{Impact \times Confidence}}{{Effort}}
   \]

2. **Prioritizing hypotheses using RICE**: 
   The "Reach" factor was added to the analysis, using the formula:
   \[
   RICE = \frac{{Reach \times Impact \times Confidence}}{{Effort}}
   \]

3. **Prioritization comparison**:
   The results were compared between both methods, highlighting differences in hypothesis ranking due to the inclusion of "Reach" in the RICE framework. This allowed the identification of hypotheses that, although requiring more effort, had a greater potential impact on a larger number of users.

## Part 2: A/B Test Analysis

In this part, I analyzed the results of an A/B test that evaluated two groups of users (A and B) to determine the impact of certain changes on revenue.

### Analysis Performed:

1. **Cumulative revenue by group**:
   - Cumulative revenue for each group was plotted to observe how it evolved over time.
   - Conjectures were made about possible differences between groups A and B.

2. **Cumulative average order size**:
   - The average order size for both groups was plotted, and the differences were analyzed.

3. **Relative difference in cumulative average order size**:
   - The relative difference in average order sizes between groups A and B was plotted over time.

4. **Daily conversion rate**:
   - The daily conversion rate (number of orders/number of visits) was calculated and compared between the two groups.

5. **Scatter plot of the number of orders per user**:
   - The 95th and 99th percentiles of the number of orders per user were analyzed to identify potential anomalies.

6. **Scatter plot of order prices**:
   - The 95th and 99th percentiles of order prices were analyzed to define anomalous data points.

### Statistical Analysis:

1. **Statistical significance**:
   - The statistical significance of the differences in conversion rates and average order sizes between groups A and B was calculated, using both the original data and the filtered data (after removing anomalies).

### Conclusion:

After analyzing the results of the A/B test and applying statistical significance tests, the possible decisions are:
1. **Stop the test** and consider one of the groups as the winner.
2. **Stop the test**, concluding that there is no significant difference between the groups.
3. **Continue the test** if the results are inconclusive.

## Project Contents

- `notebooks/`: Contains the Jupyter Notebooks with the detailed analysis.
- `datasets/`: Contains the datasets used in the analysis.
- `README.md`: This file containing the complete project description.

## Installation and Usage

To reproduce the analysis:

1. Clone this repository:
   ```bash
   git clone https://github.com/704k0-dev/a_b_test_shop.git
   ```

2. Install the necessary dependencies (using Conda or pip):
   ```bash
   conda env create -f environment.yml
   conda activate data_analysis
   ```

3. Run the notebook:
   ```bash
   jupyter notebook
   ```

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.
